# Download and Place Llama2-7b Model

To use this project, you need to download and place the Llama2-7b language model in the models folder. Follow the instructions below:

1. Download the Llama2-7b model from the provided link:
   [Download Llama2-7b Model](https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/resolve/main/llama-2-7b-chat.ggmlv3.q8_0.bin?download=true)

2. Once downloaded, move the model file (`llama-2-7b-chat.ggmlv3.q8_0.bin`) to the `models` folder in the root directory of the project.

Your project structure should look like this:

```
Lama2-7b-Langchain
├── app.py
├── models/
│   └── llama-2-7b-chat.ggmlv3.q8_0.bin
├── files/
│   └── pdf_file.pdf
└── requirements.txt
```


Now, you are ready to run the web application with the required language model.
